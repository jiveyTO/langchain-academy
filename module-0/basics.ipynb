{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "660ce795-9307-4c2c-98a1-beabcb36c740",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-0/basics.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/56295530-getting-set-up-video-guide)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef597741-3211-4ecc-92f7-f58023ee237e",
   "metadata": {},
   "source": [
    "# LangChain Academy\n",
    "\n",
    "Welcome to LangChain Academy! \n",
    "\n",
    "## Context\n",
    "\n",
    "At LangChain, we aim to make it easy to build LLM applications. One type of LLM application you can build is an agent. There’s a lot of excitement around building agents because they can automate a wide range of tasks that were previously impossible. \n",
    "\n",
    "In practice though, it is incredibly difficult to build systems that reliably execute on these tasks. As we’ve worked with our users to put agents into production, we’ve learned that more control is often necessary. You might need an agent to always call a specific tool first or use different prompts based on its state. \n",
    "\n",
    "To tackle this problem, we’ve built [LangGraph](https://langchain-ai.github.io/langgraph/) — a framework for building agent and multi-agent applications. Separate from the LangChain package, LangGraph’s core design philosophy is to help developers add better precision and control into agent workflows, suitable for the complexity of real-world systems.\n",
    "\n",
    "## Course Structure\n",
    "\n",
    "The course is structured as a set of modules, with each module focused on a particular theme related to LangGraph. You will see a folder for each module, which contains a series of notebooks. A video will accompany each notebook to help walk through the concepts, but the notebooks are also stand-alone, meaning that they contain explanations and can be viewed independently of the videos. Each module folder also contains a `studio` folder, which contains a set of graphs that can be loaded into [LangGraph Studio](https://github.com/langchain-ai/langgraph-studio), our IDE for building LangGraph applications.\n",
    "\n",
    "## Setup\n",
    "\n",
    "Before you begin, please follow the instructions in the `README` to create an environment and install dependencies.\n",
    "\n",
    "## Chat models\n",
    "\n",
    "In this course, we'll be using [Chat Models](https://python.langchain.com/v0.2/docs/concepts/#chat-models), which do a few things take a sequence of messages as inputs and return chat messages as outputs. LangChain does not host any Chat Models, rather we rely on third party integrations. [Here](https://python.langchain.com/v0.2/docs/integrations/chat/) is a list of 3rd party chat model integrations within LangChain! By default, the course will use [ChatOpenAI](https://python.langchain.com/v0.2/docs/integrations/chat/openai/) because it is both popular and performant. As noted, please ensure that you have an `OPENAI_API_KEY`.\n",
    "\n",
    "Let's check that your `OPENAI_API_KEY` is set and, if not, you will be asked to enter it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f9a52c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langchain_openai langchain_core langchain_community tavily-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2a15227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "959552b9-da30-42e8-bd22-f3f77f7833a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY:  ········\n"
     ]
    }
   ],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str, overwrite=False):\n",
    "    if overwrite or not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "    else:\n",
    "        print(f\"{var} is already set. Use `overwrite=True` to update.\")\n",
    "\n",
    "# Call the function to set or update the OPENAI_API_KEY\n",
    "_set_env(\"OPENAI_API_KEY\", overwrite=True)  # Set overwrite=True to replace the existing key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "faa026f8-2c46-4268-bc70-0b40bae13149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY: sk-pro...YBkA\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def echo_api_key(var: str):\n",
    "    api_key = os.environ.get(var)\n",
    "    if api_key:\n",
    "        # Print only the first 4 and last 4 characters of the key for confirmation\n",
    "        print(f\"{var}: {api_key[:6]}...{api_key[-4:]}\")\n",
    "    else:\n",
    "        print(f\"{var} is not set.\")\n",
    "\n",
    "# Call the function to check if the key is correct\n",
    "echo_api_key(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a326f35b",
   "metadata": {},
   "source": [
    "[Here](https://python.langchain.com/v0.2/docs/how_to/#chat-models) is a useful how-do for all the things that you can do with chat models, but we'll show a few highlights below. If you've run `pip install -r requirements.txt` as noted in the README, then you've installed the `langchain-openai` package. With this, we can instantiate our `ChatOpenAI` model object. If you are signing up for the API for the first time, you should receive [free credits](https://community.openai.com/t/understanding-api-limits-and-free-tier/498517) that can be applied to any of the models. You can see pricing for various models [here](https://openai.com/api/pricing/). The notebooks will default to `gpt-4o` because it's a good balance of quality, price, and speed [see more here](https://help.openai.com/en/articles/7102672-how-can-i-access-gpt-4-gpt-4-turbo-gpt-4o-and-gpt-4o-mini), but you can also opt for the lower priced `gpt-3.5` series models. \n",
    "\n",
    "There are [a few standard parameters](https://python.langchain.com/v0.2/docs/concepts/#chat-models) that we can set with chat models. Two of the most common are:\n",
    "\n",
    "* `model`: the name of the model\n",
    "* `temperature`: the sampling temperature\n",
    "\n",
    "`Temperature` controls the randomness or creativity of the model's output where low temperature (close to 0) is more deterministic and focused outputs. This is good for tasks requiring accuracy or factual responses. High temperature (close to 1) is good for creative tasks or generating varied responses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e19a54d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "gpt4o_chat = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "gpt35_chat = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28450d1b",
   "metadata": {},
   "source": [
    "Chat models in LangChain have a number of [default methods](https://python.langchain.com/v0.2/docs/concepts/#runnable-interface). For the most part, we'll be using:\n",
    "\n",
    "* `stream`: stream back chunks of the response\n",
    "* `invoke`: call the chain on an input\n",
    "\n",
    "And, as mentioned, chat models take [messages](https://python.langchain.com/v0.2/docs/concepts/#messages) as input. Messages have a role (that describes who is saying the message) and a content property. We'll be talking a lot more about this later, but here let's just show the basics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1280e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 11, 'total_tokens': 20, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_5796ac6771', 'finish_reason': 'stop', 'logprobs': None}, id='run-062245cf-b9ec-4b15-90fe-67f97faa4336-0', usage_metadata={'input_tokens': 11, 'output_tokens': 9, 'total_tokens': 20})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Create a message\n",
    "msg = HumanMessage(content=\"Hello world\", name=\"Lance\")\n",
    "\n",
    "# Message list\n",
    "messages = [msg]\n",
    "\n",
    "# Invoke the model with a list of messages \n",
    "gpt4o_chat.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac73e4c",
   "metadata": {},
   "source": [
    "We get an `AIMessage` response. Also, note that we can just invoke a chat model with a string. When a string is passed in as input, it is converted to a `HumanMessage` and then passed to the underlying model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f27c6c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Choosing a good smoke alarm for your house depends on several factors, including the type of smoke alarm, power source, additional features, and your budget. Here are some highly recommended options across different categories:\\n\\n### Types of Smoke Alarms\\n1. **Ionization Smoke Alarms**: Best for detecting fast-flaming fires.\\n2. **Photoelectric Smoke Alarms**: Best for detecting slow, smoldering fires.\\n3. **Dual-Sensor Smoke Alarms**: Combine both ionization and photoelectric sensors for comprehensive coverage.\\n\\n### Power Source\\n1. **Battery-Powered**: Easy to install but require regular battery changes.\\n2. **Hardwired**: Connected to your home's electrical system and often come with battery backup.\\n\\n### Recommended Models\\n\\n#### Dual-Sensor Smoke Alarms\\n- **First Alert BRK 3120B**: This hardwired model with battery backup combines both ionization and photoelectric sensors, providing comprehensive fire detection.\\n\\n#### Photoelectric Smoke Alarms\\n- **First Alert SA511CN2-3ST**: This battery-operated model features a photoelectric sensor and wireless interconnectivity, allowing you to link multiple alarms.\\n\\n#### Ionization Smoke Alarms\\n- **Kidde i12060**: A hardwired model with battery backup, known for its reliability and ease of installation.\\n\\n### Smart Smoke Alarms\\n- **Nest Protect**: This smart smoke and carbon monoxide detector offers both photoelectric smoke detection and CO detection. It connects to your Wi-Fi, sends alerts to your smartphone, and has a self-testing feature.\\n\\n### Combination Smoke and Carbon Monoxide Alarms\\n- **First Alert SCO501CN-3ST**: This battery-operated model features both smoke and carbon monoxide detection, with voice alerts to specify the type of danger.\\n\\n### Additional Features to Consider\\n- **Interconnectivity**: Allows multiple alarms to communicate with each other, so if one detects smoke, all alarms will sound.\\n- **Voice Alerts**: Some models provide voice alerts specifying the type of danger (smoke or CO).\\n- **Smart Features**: Integration with home automation systems, smartphone alerts, and self-testing capabilities.\\n- **Battery Life**: Models with 10-year sealed batteries reduce the need for frequent battery changes.\\n\\n### Budget Options\\n- **Kidde i9050**: A basic, battery-operated ionization smoke alarm that is affordable and easy to install.\\n- **First Alert SA303CN3**: Another budget-friendly, battery-operated ionization smoke alarm.\\n\\n### Installation Tips\\n- Install smoke alarms on every level of your home, including the basement.\\n- Place alarms inside each bedroom and outside sleeping areas.\\n- Test your smoke alarms monthly and replace batteries at least once a year unless you have a model with a 10-year sealed battery.\\n\\nBy considering these factors and options, you can choose a smoke alarm that best fits your needs and ensures the safety of your home.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 592, 'prompt_tokens': 19, 'total_tokens': 611, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_057232b607', 'finish_reason': 'stop', 'logprobs': None}, id='run-f9f5a3d2-0818-4548-949c-072b5ddc37d6-0', usage_metadata={'input_tokens': 19, 'output_tokens': 592, 'total_tokens': 611})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt4o_chat.invoke(\"what is a good smoke alarm to buy for my house?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fdc2f0ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 9, 'total_tokens': 18, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-15024c19-8483-4506-adf2-d43b57d984dc-0', usage_metadata={'input_tokens': 9, 'output_tokens': 9, 'total_tokens': 18})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt35_chat.invoke(\"hello world\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582c0e5a",
   "metadata": {},
   "source": [
    "The interface is consistent across all chat models and models are typically initialized once at the start up each notebooks. \n",
    "\n",
    "So, you can easily switch between models without changing the downstream code if you have strong preference for another provider.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad0069a",
   "metadata": {},
   "source": [
    "## Search Tools\n",
    "\n",
    "You'll also see [Tavily](https://tavily.com/) in the README, which is a search engine optimized for LLMs and RAG, aimed at efficient, quick, and persistent search results. As mentioned, it's easy to sign up and offers a generous free tier. Some lessons (in Module 4) will use Tavily by default but, of course, other search tools can be used if you want to modify the code for yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "091dff13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "TAVILY_API_KEY:  ········\n"
     ]
    }
   ],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str, overwrite=False):\n",
    "    if overwrite or not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "    else:\n",
    "        print(f\"{var} is already set. Use `overwrite=True` to update.\")\n",
    "        \n",
    "_set_env(\"TAVILY_API_KEY\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "52d69da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "tavily_search = TavilySearchResults(max_results=3)\n",
    "search_docs = tavily_search.invoke(\"Who are the Blue Jays?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d06f87e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://en.wikipedia.org/wiki/Toronto_Blue_Jays',\n",
       "  'content': 'The Toronto Blue Jays are a Canadian professional baseball team based in Toronto.The Blue Jays compete in Major League Baseball (MLB) as a member club of the American League (AL) East Division.Since 1989, the team has played its home games primarily at Rogers Centre in downtown Toronto.. The name \"Blue Jays\" originates from the bird of the same name, and blue is also the traditional colour of ...'},\n",
       " {'url': 'https://www.mlb.com/bluejays',\n",
       "  'content': 'The official website of the Toronto Blue Jays with the most up-to-date information on scores, schedule, stats, tickets, and team news.'},\n",
       " {'url': 'https://sports.yahoo.com/clase-hits-1st-career-hr-015125831.html',\n",
       "  'content': \"Toronto Blue Jays' Jonatan Clase, left, is doused by teammate Luis De Los Santos following their victory over the Boston Red Sox in an MLB baseball game in Toronto on Wednesday, Sept. 25, 2024.\"}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafd7d5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
